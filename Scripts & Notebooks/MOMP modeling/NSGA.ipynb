{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "# 文件路径\n",
    "mdd_path = 'C:/Users/74101/Desktop/成人抑郁症/result/12.5/result/mdd_all/cv_allrna.csv'\n",
    "bd_path = 'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_bp/cv_allrna.csv'\n",
    "hc_path = 'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_mdd/cv_allrna.csv'\n",
    "hamd_path = 'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_hmad/cv_allrna.csv'\n",
    "\n",
    "# 读取每个文件\n",
    "MDD = pd.read_csv(mdd_path)\n",
    "BD = pd.read_csv(bd_path)\n",
    "HC = pd.read_csv(hc_path)\n",
    "HAMD = pd.read_csv(hamd_path)\n",
    "\n",
    "# 按 'Model' 分组并计算均值\n",
    "MDD = MDD.groupby('Model').mean(numeric_only=True).reset_index()\n",
    "BD = BD.groupby('Model').mean(numeric_only=True).reset_index()\n",
    "HC = HC.groupby('Model').mean(numeric_only=True).reset_index()\n",
    "HAMD = HAMD.groupby('Model').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 数据整理为字典\n",
    "data_dict = {\n",
    "    \"MDD\": MDD,\n",
    "    \"BD\": BD,\n",
    "    \"HC\": HC,\n",
    "    \"HAMD\": HAMD\n",
    "}\n",
    "\n",
    "# 动态提取性能指标列（除去 \"Model\"）\n",
    "objectives = [\"AUC\", \"F1 Score\", \"Accuracy\", 'Sensitivity', 'Specificity']\n",
    "print(\"目标列:\", objectives)\n",
    "\n",
    "# 获取所有模型类型\n",
    "all_models = list(MDD[\"Model\"].unique())\n",
    "\n",
    "# 定义多目标优化问题\n",
    "class MultiObjectiveModelSelection(ElementwiseProblem):\n",
    "    def __init__(self, data_dict, all_models, objectives):\n",
    "        self.data_dict = data_dict\n",
    "        self.all_models = all_models\n",
    "        self.objectives = objectives\n",
    "        n_var = len(all_models)  # 决策变量数量（模型数量）\n",
    "        n_obj = len(objectives)  # 目标数量（性能指标数量）\n",
    "        super().__init__(n_var=n_var, n_obj=n_obj, xl=0, xu=1, type_var=float)  # 修改为float\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        # 将 x 转换为二进制选择\n",
    "        x_binary = np.round(x).astype(int)\n",
    "        selected_models = [self.all_models[i] for i, selected in enumerate(x_binary) if selected == 1]\n",
    "        \n",
    "        if not selected_models:\n",
    "            # 如果未选中任何模型，返回性能值最差的情况\n",
    "            out[\"F\"] = [1.0] * len(self.objectives)  # 所有目标设为 1（最差性能）\n",
    "            return\n",
    "        \n",
    "        scores = []\n",
    "        for obj in self.objectives:\n",
    "            obj_scores = []\n",
    "            for dataset in self.data_dict.values():\n",
    "                # 筛选当前数据集中的选中模型\n",
    "                selected_data = dataset[dataset[\"Model\"].isin(selected_models)]\n",
    "                if selected_data.empty:\n",
    "                    obj_scores.append(1.0)  # 若无选中模型，目标值为 1\n",
    "                else:\n",
    "                    # 计算选中模型的平均性能并取负值（目标最小化）\n",
    "                    obj_scores.append(-selected_data[obj].mean())\n",
    "            scores.append(np.mean(obj_scores))  # 对所有数据集取平均\n",
    "        out[\"F\"] = scores\n",
    "\n",
    "# 定义优化问题\n",
    "problem = MultiObjectiveModelSelection(data_dict, all_models, objectives)\n",
    "\n",
    "# 设置参考方向和算法\n",
    "ref_dirs = get_reference_directions(\"das-dennis\", n_dim=len(objectives), n_partitions=3)\n",
    "algorithm = NSGA3(pop_size=100, ref_dirs=ref_dirs)\n",
    "\n",
    "# 执行优化\n",
    "res = minimize(problem, algorithm, ('n_gen', 100), seed=42, verbose=True)\n",
    "\n",
    "# 解析结果\n",
    "for i, solution in enumerate(res.X):\n",
    "    # 找到最大概率的模型索引\n",
    "    max_index = np.argmax(solution)\n",
    "    selected_model = all_models[max_index]\n",
    "    print(f\"Solution {i + 1}: Selected model type: {selected_model}\")\n",
    "\n",
    "# 如果你只需要最优解的选择，可以使用：\n",
    "optimal_solution = res.X[0]\n",
    "max_index = np.argmax(optimal_solution)\n",
    "selected_model = all_models[max_index]\n",
    "print(f\"Best solution selected model type: {selected_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 外部筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 导入数据\n",
    "data_row = pd.read_csv('C:/Users/74101/Desktop/成人抑郁症/data/all.csv', encoding='GBK')\n",
    "\n",
    "# 数据分组\n",
    "train_data = data_row[data_row.iloc[:, 0].str.startswith('train')]\n",
    "test_data = data_row[data_row.iloc[:, 0].str.startswith('test')]\n",
    "\n",
    "# 定义分组逻辑的通用函数\n",
    "def process_data(data, group_filter, replace_map, drop_columns):\n",
    "    \"\"\"\n",
    "    按组过滤和处理数据。\n",
    "\n",
    "    :param data: 原始数据\n",
    "    :param group_filter: 筛选组的条件列表\n",
    "    :param replace_map: group 列的替换映射\n",
    "    :param drop_columns: 需要移除的列\n",
    "    :return: 处理后的特征和标签\n",
    "    \"\"\"\n",
    "    filtered_data = data[data['group'].isin(group_filter)]\n",
    "    filtered_data['group'] = filtered_data['group'].replace(replace_map)\n",
    "    group = filtered_data['group']\n",
    "    features = filtered_data.drop(columns=drop_columns)\n",
    "\n",
    "    # 替换所有NaN为0\n",
    "    features = features.fillna(0)\n",
    "\n",
    "    return features, group\n",
    "\n",
    "# 公共需要移除的列\n",
    "common_drop_columns = ['allRNA', 'Hospital', 'Sample_id', 'Company', 'Batch', 'group', 'Age', 'HAMD', 'Diagnosis', 'Gender']\n",
    "\n",
    "# MDD 数据\n",
    "train_mdd_feature, train_mdd_group = process_data(\n",
    "    train_data, group_filter=[3, 1, 0], replace_map={3: 0}, drop_columns=common_drop_columns)\n",
    "test_mdd_feature, test_mdd_group = process_data(\n",
    "    test_data, group_filter=[3, 1, 0], replace_map={3: 0}, drop_columns=common_drop_columns)\n",
    "\n",
    "# BD 数据\n",
    "train_bd_feature, train_bd_group = process_data(\n",
    "    train_data, group_filter=[2, 1], replace_map={2: 0}, drop_columns=common_drop_columns)\n",
    "test_bd_feature, test_bd_group = process_data(\n",
    "    test_data, group_filter=[2, 1], replace_map={2: 0}, drop_columns=common_drop_columns)\n",
    "\n",
    "# HC 数据\n",
    "train_hc_feature, train_hc_group = process_data(\n",
    "    train_data, group_filter=[1, 0], replace_map={}, drop_columns=common_drop_columns)\n",
    "test_hc_feature, test_hc_group = process_data(\n",
    "    test_data, group_filter=[1, 0], replace_map={}, drop_columns=common_drop_columns)\n",
    "\n",
    "# Other 数据\n",
    "train_other_feature, train_other_group = process_data(\n",
    "    train_data, group_filter=[3, 1], replace_map={3: 0}, drop_columns=common_drop_columns)\n",
    "test_other_feature, test_other_group = process_data(\n",
    "    test_data, group_filter=[3, 1], replace_map={3: 0}, drop_columns=common_drop_columns)\n",
    "\n",
    "# HAMD 数据\n",
    "train_hamd = train_data[train_data['group'].isin([1, 0])]\n",
    "test_hamd = test_data[test_data['group'].isin([1, 0])]\n",
    "\n",
    "# 选择 'HAMD' 非空的行\n",
    "train_hamd_filtered = train_hamd[train_hamd['HAMD'].notna()].copy()\n",
    "test_hamd_filtered = test_hamd[test_hamd['HAMD'].notna()].copy()\n",
    "\n",
    "# 将 'HAMD' 列的值按照范围分组：8-20 的标注为 0，超过 20 的标注为 1\n",
    "train_hamd_filtered['HAMD_Group'] = train_hamd_filtered['HAMD'].apply(lambda x: 0 if x < 20 else 1)\n",
    "test_hamd_filtered['HAMD_Group'] = test_hamd_filtered['HAMD'].apply(lambda x: 0 if x < 20 else 1)\n",
    "\n",
    "# 提取特征和分组信息\n",
    "train_hamd_feature = train_hamd_filtered.drop(columns=[\n",
    "    'allRNA', 'Hospital', 'Sample_id', 'Company', 'Batch', 'group', 'Age', 'HAMD', 'Diagnosis', 'Gender', 'HAMD_Group'\n",
    "])\n",
    "train_hamd_group = train_hamd_filtered['HAMD_Group']\n",
    "\n",
    "test_hamd_feature = test_hamd_filtered.drop(columns=[\n",
    "    'allRNA', 'Hospital', 'Sample_id', 'Company', 'Batch', 'group', 'Age', 'HAMD', 'Diagnosis', 'Gender', 'HAMD_Group'\n",
    "])\n",
    "test_hamd_group = test_hamd_filtered['HAMD_Group']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import joblib\n",
    "\n",
    "# 模型名称列表\n",
    "model_names = ['AdaBoost', 'CatBoost', 'GBDT', 'LightGBM', 'Logistic Regression', \n",
    "               'MLP', 'Random Forest', 'SVM', 'XGBoost']\n",
    "\n",
    "# MDD 模型\n",
    "mdd_models = {}\n",
    "for name in model_names:\n",
    "    model_path = f'C:/Users/74101/Desktop/成人抑郁症/result/12.5/result/mdd_all/model/{name}_model.pkl'\n",
    "    try:\n",
    "        mdd_models[name] = joblib.load(model_path)\n",
    "        print(f\"{name} model (MDD) loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name} model (MDD): {e}\")\n",
    "\n",
    "# BD 模型\n",
    "bd_models = {}\n",
    "for name in model_names:\n",
    "    model_path = f'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_bp/model/{name}_model.pkl'\n",
    "    try:\n",
    "        bd_models[name] = joblib.load(model_path)\n",
    "        print(f\"{name} model (BD) loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name} model (BD): {e}\")\n",
    "\n",
    "# HC 模型\n",
    "hc_models = {}\n",
    "for name in model_names:\n",
    "    model_path = f'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_mdd/model/{name}_model.pkl'\n",
    "    try:\n",
    "        hc_models[name] = joblib.load(model_path)\n",
    "        print(f\"{name} model (HC) loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name} model (HC): {e}\")\n",
    "\n",
    "# Other 模型\n",
    "other_models = {}\n",
    "for name in model_names:\n",
    "    model_path = f'C:/Users/74101/Desktop/成人抑郁症/result/12.5/result/other_all/model/{name}_model.pkl'\n",
    "    try:\n",
    "        other_models[name] = joblib.load(model_path)\n",
    "        print(f\"{name} model (Other) loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name} model (Other): {e}\")\n",
    "\n",
    "# HAMD 模型\n",
    "\n",
    "hamd_models = {}\n",
    "for name in model_names:\n",
    "    model_path = f'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_hmad/model/{name}_model.pkl'\n",
    "    try:\n",
    "        hamd_models[name] = joblib.load(model_path)\n",
    "        print(f\"{name} model (HAMD) loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name} model (HAMD): {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"MDD\": mdd_models,\n",
    "    \"BD\": bd_models,\n",
    "    \"HC\": hc_models,\n",
    "    \"Other\": other_models,\n",
    "    \"HAMD\": hamd_models\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    \"MDD\": (test_mdd_feature, test_mdd_group),\n",
    "    \"BD\": (test_bd_feature, test_bd_group),\n",
    "    \"HC\": (test_hc_feature, test_hc_group),\n",
    "    \"Other\": (test_other_feature, test_other_group),\n",
    "    \"HAMD\": (test_hamd_feature, test_hamd_group)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, average_precision_score, log_loss, matthews_corrcoef\n",
    "import pandas as pd\n",
    "\n",
    "# 定义性能评估函数\n",
    "def evaluate_model_performance(models_dict, dataset):\n",
    "    \"\"\"\n",
    "    对模型在指定数据集上进行评估。\n",
    "    \n",
    "    :param models_dict: 字典，键为数据集名称，值为模型列表\n",
    "    :param dataset: 字典，键为数据集名称，值为 (特征, 标签)\n",
    "    :return: 各模型的性能结果\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for name, models in models_dict.items():\n",
    "        # 获取对应数据集\n",
    "        test_features, test_labels = dataset[name]\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # 模型预测概率和类别\n",
    "            y_pred_prob = model.predict_proba(test_features)[:, 1]  # 获取正类的预测概率\n",
    "            y_pred = model.predict(test_features)  # 获取预测标签\n",
    "\n",
    "            # 计算各项指标\n",
    "            auc = roc_auc_score(test_labels, y_pred_prob)\n",
    "            acc = accuracy_score(test_labels, y_pred)\n",
    "            sn = recall_score(test_labels, y_pred)  # 敏感性 (召回率)\n",
    "            sp = specificity_score(test_labels, y_pred)  # 特异性\n",
    "            f1 = f1_score(test_labels, y_pred)\n",
    "            auprc = average_precision_score(test_labels, y_pred_prob)  # 精确率-召回率曲线下的面积\n",
    "            logloss = log_loss(test_labels, y_pred_prob)  # 对数损失\n",
    "            mcc = matthews_corrcoef(test_labels, y_pred)  # 马修斯相关系数\n",
    "\n",
    "            # 保存结果\n",
    "            results.append({\n",
    "                \"Dataset\": name,\n",
    "                \"Model\": model_name,\n",
    "                \"AUC\": auc,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Sensitivity (SN)\": sn,\n",
    "                \"Specificity (SP)\": sp,\n",
    "                \"F1 Score\": f1,\n",
    "                \"AUPRC\": auprc,\n",
    "                \"Log-Loss\": logloss,\n",
    "                \"MCC\": mcc\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 定义计算特异性的辅助函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算特异性。\n",
    "    \n",
    "    :param y_true: 真实标签\n",
    "    :param y_pred: 预测标签\n",
    "    :return: 特异性\n",
    "    \"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# 调用评估函数\n",
    "performance_results = evaluate_model_performance(models_dict, dataset)\n",
    "\n",
    "# 打印或保存结果\n",
    "print(performance_results)\n",
    "performance_results.to_csv('C:/Users/74101/Desktop/成人抑郁症/result/12.5/result/model_performance1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSGA3\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# 提取性能指标和模型\n",
    "objectives = [\"AUC\", \"AUPRC\", \"Log-Loss\", \"MCC\"]\n",
    "datasets = performance_results[\"Dataset\"].unique()\n",
    "models = performance_results[\"Model\"].unique()\n",
    "\n",
    "# 数据预处理为字典形式\n",
    "data_dict = {\n",
    "    dataset: performance_results[performance_results[\"Dataset\"] == dataset]\n",
    "    for dataset in datasets\n",
    "}\n",
    "\n",
    "# 定义多目标优化问题\n",
    "class ModelSelectionProblem(ElementwiseProblem):\n",
    "    def __init__(self, data_dict, models, objectives):\n",
    "        self.data_dict = data_dict\n",
    "        self.models = models\n",
    "        self.objectives = objectives\n",
    "        n_var = len(models)  # 决策变量（模型数量）\n",
    "        n_obj = len(objectives)  # 目标数量\n",
    "        super().__init__(n_var=n_var, n_obj=n_obj, xl=0, xu=1, type_var=float)  # 使用浮点型变量\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        x_binary = np.round(x).astype(int)  # 将浮点数转换为二进制选择\n",
    "        selected_models = [self.models[i] for i, selected in enumerate(x_binary) if selected == 1]\n",
    "\n",
    "        if not selected_models:\n",
    "            # 如果未选中任何模型，返回最差性能\n",
    "            out[\"F\"] = [1.0] * len(self.objectives)  # 所有目标最差性能\n",
    "            return\n",
    "\n",
    "        scores = []\n",
    "        for obj in self.objectives:\n",
    "            obj_scores = []\n",
    "            for dataset, data in self.data_dict.items():\n",
    "                # 筛选选中模型\n",
    "                selected_data = data[data[\"Model\"].isin(selected_models)]\n",
    "                if selected_data.empty:\n",
    "                    obj_scores.append(1.0)  # 无选中模型，性能为最差\n",
    "                else:\n",
    "                    # 计算选中模型的平均性能并取负值\n",
    "                    obj_scores.append(-selected_data[obj].mean())\n",
    "            scores.append(np.mean(obj_scores))  # 对所有数据集取平均\n",
    "        out[\"F\"] = scores\n",
    "\n",
    "# 定义优化问题\n",
    "problem = ModelSelectionProblem(data_dict, models, objectives)\n",
    "\n",
    "# 设置参考方向和算法\n",
    "ref_dirs = get_reference_directions(\"das-dennis\", n_dim=len(objectives), n_partitions=6)\n",
    "algorithm = NSGA3(pop_size=210, ref_dirs=ref_dirs)\n",
    "\n",
    "# 执行优化\n",
    "res = minimize(problem, algorithm, ('n_gen', 100), seed=42, verbose=True)\n",
    "\n",
    "# 输出 Pareto 解\n",
    "optimal_solutions = res.X\n",
    "for i, solution in enumerate(optimal_solutions):\n",
    "    selected_models = [models[j] for j in range(len(models)) if np.round(solution[j]) == 1]\n",
    "    print(f\"Solution {i + 1}: Selected models: {selected_models}\")\n",
    "\n",
    "# 选择最佳解\n",
    "best_solution = optimal_solutions[0]\n",
    "selected_models = [models[j] for j in range(len(models)) if np.round(best_solution[j]) == 1]\n",
    "print(f\"Best solution: Selected models: {selected_models}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSGA3\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# 提取性能指标和模型\n",
    "objectives = [\"AUC\", \"AUPRC\", \"Log-Loss\", \"MCC\"]\n",
    "datasets = performance_results[\"Dataset\"].unique()\n",
    "models = performance_results[\"Model\"].unique()\n",
    "\n",
    "# 数据预处理为字典形式\n",
    "data_dict = {\n",
    "    dataset: performance_results[performance_results[\"Dataset\"] == dataset]\n",
    "    for dataset in datasets\n",
    "}\n",
    "\n",
    "# 定义多目标优化问题\n",
    "class ModelSelectionProblem(ElementwiseProblem):\n",
    "    def __init__(self, data_dict, models, objectives):\n",
    "        self.data_dict = data_dict\n",
    "        self.models = models\n",
    "        self.objectives = objectives\n",
    "        n_var = len(models)  # 决策变量（模型数量）\n",
    "        n_obj = len(objectives)  # 目标数量\n",
    "        super().__init__(n_var=n_var, n_obj=n_obj, xl=0, xu=1, type_var=float)  # 使用浮点型变量\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        x_binary = np.round(x).astype(int)  # 将浮点数转换为二进制选择\n",
    "        selected_models = [self.models[i] for i, selected in enumerate(x_binary) if selected == 1]\n",
    "\n",
    "        if not selected_models:\n",
    "            # 如果未选中任何模型，返回最差性能\n",
    "            out[\"F\"] = [1.0] * len(self.objectives)  # 所有目标最差性能\n",
    "            return\n",
    "\n",
    "        scores = []\n",
    "        for obj in self.objectives:\n",
    "            obj_scores = []\n",
    "            for dataset, data in self.data_dict.items():\n",
    "                # 筛选选中模型\n",
    "                selected_data = data[data[\"Model\"].isin(selected_models)]\n",
    "                if selected_data.empty:\n",
    "                    obj_scores.append(1.0)  # 无选中模型，性能为最差\n",
    "                else:\n",
    "                    # 计算选中模型的平均性能并取负值\n",
    "                    obj_scores.append(-selected_data[obj].mean())\n",
    "            scores.append(np.mean(obj_scores))  # 对所有数据集取平均\n",
    "        out[\"F\"] = scores\n",
    "\n",
    "# 定义优化问题\n",
    "problem = ModelSelectionProblem(data_dict, models, objectives)\n",
    "\n",
    "# 设置参考方向和算法\n",
    "ref_dirs = get_reference_directions(\"das-dennis\", n_dim=len(objectives), n_partitions=6)\n",
    "algorithm = NSGA3(pop_size=100, ref_dirs=ref_dirs)\n",
    "\n",
    "# 执行优化\n",
    "res = minimize(problem, algorithm, ('n_gen', 100), seed=42, verbose=True)\n",
    "\n",
    "# 输出 Pareto 解\n",
    "optimal_solutions = res.X\n",
    "optimal_objectives = res.F  # Pareto 前沿解的目标值\n",
    "\n",
    "# 获取所有解的 AUC 值，并按 AUC 排序\n",
    "auc_values = optimal_objectives[:, 0]  # 假设 AUC 是第一个目标（根据 objectives 列表中的顺序）\n",
    "best_solution_index = np.argmin(auc_values)  # 找到最大 AUC 的解的索引\n",
    "\n",
    "# 获取对应 AUC 最大解的所有模型选择概率\n",
    "best_solution = optimal_solutions[best_solution_index]\n",
    "\n",
    "# 输出当前解的模型概率\n",
    "print(f\"Selected models based on maximum AUC: {best_solution}\")\n",
    "\n",
    "# 在这些模型中选择概率最高的模型\n",
    "max_prob_model_index = np.argmax(best_solution)  # 选择最大概率的模型索引\n",
    "selected_model = models[max_prob_model_index]  # 获取模型名称\n",
    "\n",
    "print(f\"Best model with highest probability: {selected_model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# 提取性能指标和模型\n",
    "objectives = [\"AUC\", \"AUPRC\", \"Log-Loss\"]\n",
    "datasets = performance_results[\"Dataset\"].unique()\n",
    "models = performance_results[\"Model\"].unique()\n",
    "\n",
    "# 数据预处理为字典形式\n",
    "data_dict = {\n",
    "    dataset: performance_results[performance_results[\"Dataset\"] == dataset]\n",
    "    for dataset in datasets\n",
    "}\n",
    "\n",
    "# 定义多目标优化问题\n",
    "class ModelSelectionProblem(ElementwiseProblem):\n",
    "    def __init__(self, data_dict, models, objectives):\n",
    "        self.data_dict = data_dict\n",
    "        self.models = models\n",
    "        self.objectives = objectives\n",
    "        n_var = len(models)  # 决策变量（模型数量）\n",
    "        n_obj = len(objectives)  # 目标数量\n",
    "        super().__init__(n_var=n_var, n_obj=n_obj, xl=0, xu=1, type_var=float)  # 使用浮点型变量\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        x_binary = np.round(x).astype(int)  # 将浮点数转换为二进制选择\n",
    "        selected_models = [self.models[i] for i, selected in enumerate(x_binary) if selected == 1]\n",
    "\n",
    "        if not selected_models:\n",
    "            # 如果未选中任何模型，返回最差性能\n",
    "            out[\"F\"] = [1.0] * len(self.objectives)  # 所有目标最差性能\n",
    "            return\n",
    "\n",
    "        scores = []\n",
    "        for obj in self.objectives:\n",
    "            obj_scores = []\n",
    "            for dataset, data in self.data_dict.items():\n",
    "                # 筛选选中模型\n",
    "                selected_data = data[data[\"Model\"].isin(selected_models)]\n",
    "                if selected_data.empty:\n",
    "                    obj_scores.append(1.0)  # 无选中模型，性能为最差\n",
    "                else:\n",
    "                    # 计算选中模型的平均性能并取负值（Log-Loss需要最小化）\n",
    "                    if obj == \"Log-Loss\":\n",
    "                        obj_scores.append(selected_data[obj].mean())  # Log-Loss 越小越好，保留正值\n",
    "                    else:\n",
    "                        obj_scores.append(-selected_data[obj].mean())  # AUC, AUPRC 和 MCC 越大越好，取负值\n",
    "            scores.append(np.mean(obj_scores))  # 对所有数据集取平均\n",
    "        out[\"F\"] = scores\n",
    "\n",
    "# 定义优化问题\n",
    "problem = ModelSelectionProblem(data_dict, models, objectives)\n",
    "\n",
    "# 设置参考方向和算法\n",
    "ref_dirs = get_reference_directions(\"das-dennis\", n_dim=len(objectives), n_partitions=6)\n",
    "algorithm = NSGA3(pop_size=100, ref_dirs=ref_dirs)\n",
    "\n",
    "# 执行优化\n",
    "res = minimize(problem, algorithm, ('n_gen', 100), seed=42, verbose=True)\n",
    "\n",
    "# 输出 Pareto 解\n",
    "optimal_solutions = res.X\n",
    "optimal_objectives = res.F  # Pareto 前沿解的目标值\n",
    "\n",
    "# 获取所有解的 AUC 值，并按 AUC 排序\n",
    "auc_values = optimal_objectives[:, 0]  # 假设 AUC 是第一个目标（根据 objectives 列表中的顺序）\n",
    "best_solution_index = np.argmin(auc_values)  # 找到最大 AUC 的解的索引\n",
    "\n",
    "# 获取对应 AUC 最大解的所有模型选择概率\n",
    "best_solution = optimal_solutions[best_solution_index]\n",
    "\n",
    "# 输出当前解的模型概率\n",
    "print(f\"Selected models based on maximum AUC: {best_solution}\")\n",
    "\n",
    "# 在这些模型中选择概率最高的模型\n",
    "max_prob_model_index = np.argmax(best_solution)  # 选择最大概率的模型索引\n",
    "selected_model = models[max_prob_model_index]  # 获取模型名称\n",
    "\n",
    "print(f\"Best model with highest probability: {selected_model}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
