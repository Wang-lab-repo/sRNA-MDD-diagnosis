{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, confusion_matrix, roc_curve, \n",
    "    precision_score, recall_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据读入\n",
    "mirna=pd.read_csv(r'./all_ori_new.csv',encoding='GBK')\n",
    "mirna = mirna[mirna['group'].isin([1, 0])]\n",
    "##分组\n",
    "train_mirna = mirna[mirna.iloc[:, 0].str.startswith('train')]\n",
    "test_mirna = mirna[mirna.iloc[:, 0].str.startswith('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择 'HAMD' 非空\n",
    "train_mirna_filtered = train_mirna[train_mirna['HAMD'].notna()]\n",
    "\n",
    "# 将 8-20 的行标注为 0，20 以上的行标注为 1\n",
    "train_mirna_filtered['HAMD'] = train_mirna_filtered['HAMD'].apply(lambda x: 0 if x < 17 else 1)\n",
    "\n",
    "# 提取分组和特征列\n",
    "mirna_group = train_mirna_filtered['HAMD']\n",
    "mirna_feature = train_mirna_filtered.drop(columns=['allRNA','Hospital', 'Sample_id', 'Company','Batch','group','Age', 'HAMD', 'Diagnosis', 'Gender'])\n",
    "train_mirna_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型的参数网格\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [10000]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'GNB': {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(10,), (50,), (10, 50), (50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    },\n",
    "    'GBDT': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.7, 0.8, 1.0]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.7, 0.8, 1.0]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'boosting_type': ['gbdt'],\n",
    "        'subsample': [0.7, 0.8, 1.0]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'depth': [3, 5, 7]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 定义模型\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'MLP': MLPClassifier(),\n",
    "    'GBDT': GradientBoostingClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(),\n",
    "    'LightGBM': lgb.LGBMClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# 交叉验证\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 保存最优参数和模型\n",
    "best_params = {}\n",
    "best_models = {}\n",
    "\n",
    "# 超参数优化\n",
    "for model_name, model in models.items():\n",
    "    if model_name in param_grids:\n",
    "        param_grid = param_grids[model_name]\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(mirna_feature, mirna_group)\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        model.fit(mirna_feature, mirna_group)\n",
    "        best_models[model_name] = model\n",
    "        print(f\"{model_name} has no hyperparameters to tune.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最佳参数到文件\n",
    "best_params_df = pd.DataFrame(list(best_params.items()), columns=['Model', 'Best Parameters'])\n",
    "best_params_df['Best Parameters'] = best_params_df['Best Parameters'].apply(lambda x: str(x))  # 转换为字符串\n",
    "best_params_df.to_csv('./best_params.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Best parameters saved to 'best_params.csv'\")\n",
    "\n",
    "# 扁平化字典\n",
    "best_params_flat = {model: params for model, params in best_params.items()}\n",
    "best_params_df = pd.json_normalize(best_params_flat).reset_index()\n",
    "best_params_df.rename(columns={'index': 'Model'}, inplace=True)  # 重命名索引列为 'Model'\n",
    "best_params_df.to_csv('./best_params2.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Best parameters saved to 'best_params.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, f1_score, matthews_corrcoef, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 自定义评分函数\n",
    "def sensitivity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "\n",
    "def youden_index_score(y_true, y_pred):\n",
    "    sensitivity = sensitivity_score(y_true, y_pred)\n",
    "    specificity = specificity_score(y_true, y_pred)\n",
    "    return sensitivity + specificity - 1\n",
    "\n",
    "# 交叉验证配置\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 存储交叉验证结果\n",
    "results = []\n",
    "roc_curves = {}\n",
    "\n",
    "# 对每个模型进行交叉验证\n",
    "for name, model in best_models.items():\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    sensitivity_scores = []\n",
    "    specificity_scores = []\n",
    "    youden_index_scores = []\n",
    "    ppv_scores = []\n",
    "    npv_scores = []\n",
    "    f1_scores = []\n",
    "    mcc_scores = []\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_proba_all = []\n",
    "\n",
    "    for train_index, test_index in cv.split(mirna_feature, mirna_group):\n",
    "        X_train_fold, X_test_fold = mirna_feature.iloc[train_index], mirna_feature.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = mirna_group.iloc[train_index], mirna_group.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = model.predict(X_test_fold)\n",
    "        y_pred_proba_fold = model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "        y_true_all.extend(y_test_fold)\n",
    "        y_pred_proba_all.extend(y_pred_proba_fold)\n",
    "\n",
    "        # 计算各类指标\n",
    "        auc_scores.append(roc_auc_score(y_test_fold, y_pred_proba_fold))\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred_fold))\n",
    "        sensitivity_scores.append(sensitivity_score(y_test_fold, y_pred_fold))\n",
    "        specificity_scores.append(specificity_score(y_test_fold, y_pred_fold))\n",
    "        youden_index_scores.append(youden_index_score(y_test_fold, y_pred_fold))\n",
    "        ppv_scores.append(precision_score(y_test_fold, y_pred_fold))\n",
    "        npv_scores.append(precision_score(y_test_fold, y_pred_fold, pos_label=0))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred_fold))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test_fold, y_pred_fold))\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Fold': len(auc_scores),\n",
    "            'AUC': auc_scores[-1],\n",
    "            'Accuracy': accuracy_scores[-1],\n",
    "            'Sensitivity': sensitivity_scores[-1],\n",
    "            'Specificity': specificity_scores[-1],\n",
    "            'Youden Index': youden_index_scores[-1],\n",
    "            'PPV': ppv_scores[-1],\n",
    "            'NPV': npv_scores[-1],\n",
    "            'F1 Score': f1_scores[-1],\n",
    "            'MCC': mcc_scores[-1]\n",
    "        })\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true_all, y_pred_proba_all)\n",
    "    roc_curves[name] = (fpr, tpr, roc_auc_score(y_true_all, y_pred_proba_all))\n",
    "\n",
    "# 计算置信区间\n",
    "bootstrap_iterations = 1000\n",
    "confidence_level = 95\n",
    "bootstrap_results = {name: [] for name in best_models.keys()}\n",
    "conf_intervals = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_true_all = []\n",
    "    y_pred_proba_all = []\n",
    "\n",
    "    for train_index, test_index in cv.split(mirna_feature, mirna_group):\n",
    "        X_train_fold, X_test_fold = mirna_feature.iloc[train_index], mirna_feature.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = mirna_group.iloc[train_index], mirna_group.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_proba_fold = model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "        y_true_all.extend(y_test_fold)\n",
    "        y_pred_proba_all.extend(y_pred_proba_fold)\n",
    "\n",
    "    y_true_all = np.array(y_true_all)\n",
    "    y_pred_proba_all = np.array(y_pred_proba_all)\n",
    "\n",
    "    for _ in range(bootstrap_iterations):\n",
    "        y_true_bootstrap, y_pred_proba_bootstrap = resample(y_true_all, y_pred_proba_all)\n",
    "        bootstrap_results[name].append(roc_auc_score(y_true_bootstrap, y_pred_proba_bootstrap))\n",
    "\n",
    "    lower_bound = np.percentile(bootstrap_results[name], (100 - confidence_level) / 2)\n",
    "    upper_bound = np.percentile(bootstrap_results[name], 100 - (100 - confidence_level) / 2)\n",
    "\n",
    "    conf_intervals[name] = (lower_bound, upper_bound)\n",
    "\n",
    "    print(f\"{name} AUC 95% CI: {lower_bound:.4f} - {upper_bound:.4f}\")\n",
    "\n",
    "# 计算其他指标的置信区间\n",
    "metrics = ['Accuracy', 'Sensitivity', 'Specificity', 'Youden Index', 'PPV', 'NPV', 'F1 Score', 'MCC']\n",
    "bootstrap_metrics_results = {metric: {name: [] for name in best_models.keys()} for metric in metrics}\n",
    "metrics_conf_intervals = {metric: {} for metric in metrics}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "\n",
    "    for train_index, test_index in cv.split(mirna_feature, mirna_group):\n",
    "        X_train_fold, X_test_fold = mirna_feature.iloc[train_index], mirna_feature.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = mirna_group.iloc[train_index], mirna_group.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = model.predict(X_test_fold)\n",
    "\n",
    "        y_true_all.extend(y_test_fold)\n",
    "        y_pred_all.extend(y_pred_fold)\n",
    "\n",
    "    y_true_all = np.array(y_true_all)\n",
    "    y_pred_all = np.array(y_pred_all)\n",
    "\n",
    "    # 通过bootstrapping计算每个性能指标的置信区间\n",
    "    for _ in range(bootstrap_iterations):\n",
    "        y_true_bootstrap, y_pred_bootstrap = resample(y_true_all, y_pred_all)\n",
    "        \n",
    "        bootstrap_metrics_results['Accuracy'][name].append(accuracy_score(y_true_bootstrap, y_pred_bootstrap))\n",
    "        bootstrap_metrics_results['Sensitivity'][name].append(sensitivity_score(y_true_bootstrap, y_pred_bootstrap))\n",
    "        bootstrap_metrics_results['Specificity'][name].append(specificity_score(y_true_bootstrap, y_pred_bootstrap))\n",
    "        bootstrap_metrics_results['Youden Index'][name].append(youden_index_score(y_true_bootstrap, y_pred_bootstrap))\n",
    "        bootstrap_metrics_results['PPV'][name].append(precision_score(y_true_bootstrap, y_pred_bootstrap))\n",
    "        bootstrap_metrics_results['NPV'][name].append(precision_score(y_true_bootstrap, y_pred_bootstrap, pos_label=0))\n",
    "        bootstrap_metrics_results['F1 Score'][name].append(f1_score(y_true_bootstrap, y_pred_bootstrap))\n",
    "        bootstrap_metrics_results['MCC'][name].append(matthews_corrcoef(y_true_bootstrap, y_pred_bootstrap))\n",
    "\n",
    "    # 计算95%置信区间\n",
    "    for metric in metrics:\n",
    "        lower_bound = np.percentile(bootstrap_metrics_results[metric][name], (100 - confidence_level) / 2)\n",
    "        upper_bound = np.percentile(bootstrap_metrics_results[metric][name], 100 - (100 - confidence_level) / 2)\n",
    "        metrics_conf_intervals[metric][name] = (lower_bound, upper_bound)\n",
    "        print(f\"{name} {metric} 95% CI: {lower_bound:.4f} - {upper_bound:.4f}\")\n",
    "\n",
    "# 保存结果为 CSV 文件\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('./cv_allrna.csv', index=False)\n",
    "\n",
    "print(\"Cross-validation results saved to 'cv_results.csv'\")\n",
    "\n",
    "# 保存置信区间结果\n",
    "metrics_conf_intervals_df = []\n",
    "for metric in metrics:\n",
    "    for name, (lower_bound, upper_bound) in metrics_conf_intervals[metric].items():\n",
    "        metrics_conf_intervals_df.append({\n",
    "            'Model': name,\n",
    "            'Metric': metric,\n",
    "            'Lower Bound': lower_bound,\n",
    "            'Upper Bound': upper_bound\n",
    "        })\n",
    "\n",
    "# 转换为 DataFrame 并保存为 CSV\n",
    "df_metrics_conf_intervals = pd.DataFrame(metrics_conf_intervals_df)\n",
    "df_metrics_conf_intervals.to_csv('./metrics_conf_intervals.csv', index=False)\n",
    "print(\"Metrics confidence intervals saved to 'metrics_conf_intervals.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制ROC曲线\n",
    "\n",
    "# 设置字体为Arial\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, (fpr, tpr, auc) in roc_curves.items():\n",
    "    lower_bound, upper_bound = conf_intervals[name]\n",
    "    plt.plot(fpr, tpr, label=f'{name} ( AUC = {auc:.3f} [{lower_bound:.3f}-{upper_bound:.3f}] )')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# 移除右边和上边边界\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# 保存为矢量图\n",
    "plt.savefig('./allrna10折ROC.svg', format='svg')  # 保存为SVG格式\n",
    "# plt.savefig('ROC_Curves.pdf', format='pdf')  # 保存为PDF格式（取消注释以使用）\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择 'HAMD' 非空且大于8的行\n",
    "test_mirna_filtered = test_mirna[test_mirna['HAMD'].notna()]\n",
    "\n",
    "# 将 8-20 的行标注为 0，20 以上的行标注为 1\n",
    "test_mirna_filtered['HAMD'] = test_mirna_filtered['HAMD'].apply(lambda x: 0 if x < 17 else 1)\n",
    "\n",
    "# 提取分组和特征列\n",
    "y_test = test_mirna_filtered['HAMD']\n",
    "X_test = test_mirna_filtered.drop(columns=['allRNA','Hospital', 'Sample_id', 'Company','Batch','group','Age', 'HAMD', 'Diagnosis', 'Gender'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, recall_score, confusion_matrix, precision_score, f1_score, matthews_corrcoef\n",
    "import pandas as pd\n",
    "\n",
    "# 创建一个空的列表来存储每个模型的结果\n",
    "results = []\n",
    "\n",
    "plt.figure(figsize=(10, 8))  # 创建一个新的图形\n",
    "\n",
    "# 外部验证测试\n",
    "for name, model in best_models.items():\n",
    "    # 计算模型的决策函数得分，如果没有 decision_function，则使用 predict_proba\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        y_score = model.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 计算ROC曲线参数\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    auc = roc_auc_score(y_test, y_score)\n",
    "    \n",
    "    # 计算其他指标\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sensitivity = recall_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = precision_score(y_test, y_pred)  # PPV\n",
    "    npv = tn / (tn + fn)  # NPV\n",
    "    f1 = f1_score(y_test, y_pred)  # F1 Score\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)  # MCC\n",
    "    youden_index = sensitivity + specificity - 1\n",
    "    \n",
    "    # 使用自举法计算AUC和其他性能指标的95%置信区间\n",
    "    n_bootstraps = 1000\n",
    "    auc_scores, accuracy_scores, sensitivity_scores, specificity_scores = [], [], [], []\n",
    "    ppv_scores, npv_scores, f1_scores, mcc_scores, youden_index_scores = [], [], [], [], []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # 自举采样\n",
    "        y_test_resampled, y_score_resampled = resample(y_test, y_score, random_state=np.random.randint(1, 100))\n",
    "        auc_resampled = roc_auc_score(y_test_resampled, y_score_resampled)\n",
    "        auc_scores.append(auc_resampled)\n",
    "\n",
    "        # 根据新的y_test采样重新计算性能指标\n",
    "        y_pred_resampled = np.where(y_score_resampled > 0.5, 1, 0)\n",
    "        accuracy_scores.append(accuracy_score(y_test_resampled, y_pred_resampled))\n",
    "        sensitivity_scores.append(recall_score(y_test_resampled, y_pred_resampled))\n",
    "        tn_resampled, fp_resampled, fn_resampled, tp_resampled = confusion_matrix(y_test_resampled, y_pred_resampled).ravel()\n",
    "        specificity_scores.append(tn_resampled / (tn_resampled + fp_resampled))\n",
    "        ppv_scores.append(precision_score(y_test_resampled, y_pred_resampled))\n",
    "        npv_scores.append(tn_resampled / (tn_resampled + fn_resampled))\n",
    "        f1_scores.append(f1_score(y_test_resampled, y_pred_resampled))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test_resampled, y_pred_resampled))\n",
    "        youden_index_scores.append(sensitivity_scores[-1] + specificity_scores[-1] - 1)\n",
    "    \n",
    "    # 计算各项指标的95%置信区间\n",
    "    def compute_ci(scores):\n",
    "        sorted_scores = np.array(scores)\n",
    "        sorted_scores.sort()\n",
    "        lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "        upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "        return lower, upper\n",
    "    \n",
    "    auc_ci = compute_ci(auc_scores)\n",
    "    accuracy_ci = compute_ci(accuracy_scores)\n",
    "    sensitivity_ci = compute_ci(sensitivity_scores)\n",
    "    specificity_ci = compute_ci(specificity_scores)\n",
    "    ppv_ci = compute_ci(ppv_scores)\n",
    "    npv_ci = compute_ci(npv_scores)\n",
    "    f1_ci = compute_ci(f1_scores)\n",
    "    mcc_ci = compute_ci(mcc_scores)\n",
    "    youden_index_ci = compute_ci(youden_index_scores)\n",
    "    \n",
    "    # 绘制ROC曲线\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f} [{auc_ci[0]:.3f}-{auc_ci[1]:.3f}])')\n",
    "\n",
    "    # 存储每个模型的结果，包括置信区间\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'AUC': f'{auc:.3f} [{auc_ci[0]:.3f}-{auc_ci[1]:.3f}]',\n",
    "        'Accuracy': f'{accuracy:.3f} [{accuracy_ci[0]:.3f}-{accuracy_ci[1]:.3f}]',\n",
    "        'Sensitivity': f'{sensitivity:.3f} [{sensitivity_ci[0]:.3f}-{sensitivity_ci[1]:.3f}]',\n",
    "        'Specificity': f'{specificity:.3f} [{specificity_ci[0]:.3f}-{specificity_ci[1]:.3f}]',\n",
    "        'Youden Index': f'{youden_index:.3f} [{youden_index_ci[0]:.3f}-{youden_index_ci[1]:.3f}]',\n",
    "        'PPV': f'{ppv:.3f} [{ppv_ci[0]:.3f}-{ppv_ci[1]:.3f}]',\n",
    "        'NPV': f'{npv:.3f} [{npv_ci[0]:.3f}-{npv_ci[1]:.3f}]',\n",
    "        'F1 Score': f'{f1:.3f} [{f1_ci[0]:.3f}-{f1_ci[1]:.3f}]',\n",
    "        'MCC': f'{mcc:.3f} [{mcc_ci[0]:.3f}-{mcc_ci[1]:.3f}]'\n",
    "    })\n",
    "\n",
    "# 绘制随机猜测线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "# 添加标签和图例\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=15)\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# 移除右边和上边边界\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "# 保存ROC曲线为矢量图\n",
    "plt.savefig('./allrna外部测试ROC.svg', format='svg')\n",
    "\n",
    "# 显示绘图\n",
    "plt.show()\n",
    "\n",
    "# 将结果转换为DataFrame并显示\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# 将结果数据框保存为CSV文件\n",
    "results_df.to_csv('./allrna_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义每个模型的固定颜色\n",
    "model_colors = {\n",
    "    'Random Forest': '#1f77b4',\n",
    "    'AdaBoost': '#ff7f0e',\n",
    "    'SVM': '#2ca02c',\n",
    "    'LightGBM': '#4b0082',  # 靛蓝色\n",
    "    'GBDT': '#9467bd',      # 紫罗兰色\n",
    "    'XGBoost': '#8c564b',   # 棕色\n",
    "    'CatBoost': '#e377c2',  # 粉色\n",
    "    'Logistic Regression': '#7f7f7f',  # 灰色\n",
    "    'MLP': '#bcbd22'        # 黄绿色\n",
    "}\n",
    "\n",
    "# 存储ROC数据和AUC值用于排序\n",
    "roc_data = {}\n",
    "results = []\n",
    "threshold = 0.4\n",
    "\n",
    "# 第一次循环：计算指标并收集数据\n",
    "for name, model in best_models.items():\n",
    "    # 计算模型的决策函数得分，如果没有 decision_function，则使用 predict_proba\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        y_score = model.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 计算ROC曲线参数\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    auc = roc_auc_score(y_test, y_score)\n",
    "    # 对 y_score 进行归一化到 [0, 1]\n",
    "    y_score_min = y_score.min()  # 最小值\n",
    "    y_score_max = y_score.max()  # 最大值\n",
    "    y_score = (y_score - y_score_min) / (y_score_max - y_score_min)\n",
    "    # 计算其他指标\n",
    "    y_pred = np.where(y_score > threshold, 1, 0)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sensitivity = recall_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = precision_score(y_test, y_pred)  # PPV\n",
    "    npv = tn / (tn + fn)  # NPV\n",
    "    f1 = f1_score(y_test, y_pred)  # F1 Score\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)  # MCC\n",
    "    youden_index = sensitivity + specificity - 1\n",
    "    \n",
    "    # 使用自举法计算AUC和其他性能指标的95%置信区间\n",
    "    n_bootstraps = 1000\n",
    "    auc_scores, accuracy_scores, sensitivity_scores, specificity_scores = [], [], [], []\n",
    "    ppv_scores, npv_scores, f1_scores, mcc_scores, youden_index_scores = [], [], [], [], []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # 自举采样\n",
    "        y_test_resampled, y_score_resampled = resample(y_test, y_score, random_state=np.random.randint(1, 100))\n",
    "        auc_resampled = roc_auc_score(y_test_resampled, y_score_resampled)\n",
    "        auc_scores.append(auc_resampled)\n",
    "\n",
    "        # 根据新的y_test采样重新计算性能指标\n",
    "        y_pred_resampled = np.where(y_score_resampled > threshold, 1, 0)\n",
    "        accuracy_scores.append(accuracy_score(y_test_resampled, y_pred_resampled))\n",
    "        sensitivity_scores.append(recall_score(y_test_resampled, y_pred_resampled))\n",
    "        tn_resampled, fp_resampled, fn_resampled, tp_resampled = confusion_matrix(y_test_resampled, y_pred_resampled).ravel()\n",
    "        specificity_scores.append(tn_resampled / (tn_resampled + fp_resampled))\n",
    "        ppv_scores.append(precision_score(y_test_resampled, y_pred_resampled))\n",
    "        npv_scores.append(tn_resampled / (tn_resampled + fn_resampled))\n",
    "        f1_scores.append(f1_score(y_test_resampled, y_pred_resampled))\n",
    "        mcc_scores.append(matthews_corrcoef(y_test_resampled, y_pred_resampled))\n",
    "        youden_index_scores.append(sensitivity_scores[-1] + specificity_scores[-1] - 1)\n",
    "    \n",
    "    # 计算各项指标的95%置信区间\n",
    "    def compute_ci(scores):\n",
    "        sorted_scores = np.array(scores)\n",
    "        sorted_scores.sort()\n",
    "        lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "        upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "        return lower, upper\n",
    "    \n",
    "    auc_ci = compute_ci(auc_scores)\n",
    "    accuracy_ci = compute_ci(accuracy_scores)\n",
    "    sensitivity_ci = compute_ci(sensitivity_scores)\n",
    "    specificity_ci = compute_ci(specificity_scores)\n",
    "    ppv_ci = compute_ci(ppv_scores)\n",
    "    npv_ci = compute_ci(npv_scores)\n",
    "    f1_ci = compute_ci(f1_scores)\n",
    "    mcc_ci = compute_ci(mcc_scores)\n",
    "    youden_index_ci = compute_ci(youden_index_scores)\n",
    "    \n",
    "    # 存储ROC数据\n",
    "    roc_data[name] = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'auc': auc,\n",
    "        'auc_ci': (auc_ci[0], auc_ci[1])  # 存储置信区间\n",
    "    }\n",
    "\n",
    "    # 存储每个模型的结果，包括置信区间\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'AUC': f'{auc:.3f} [{auc_ci[0]:.3f}-{auc_ci[1]:.3f}]',\n",
    "        'Accuracy': f'{accuracy:.3f} [{accuracy_ci[0]:.3f}-{accuracy_ci[1]:.3f}]',\n",
    "        'Sensitivity': f'{sensitivity:.3f} [{sensitivity_ci[0]:.3f}-{sensitivity_ci[1]:.3f}]',\n",
    "        'Specificity': f'{specificity:.3f} [{specificity_ci[0]:.3f}-{specificity_ci[1]:.3f}]',\n",
    "        'Youden Index': f'{youden_index:.3f} [{youden_index_ci[0]:.3f}-{youden_index_ci[1]:.3f}]',\n",
    "        'PPV': f'{ppv:.3f} [{ppv_ci[0]:.3f}-{ppv_ci[1]:.3f}]',\n",
    "        'NPV': f'{npv:.3f} [{npv_ci[0]:.3f}-{npv_ci[1]:.3f}]',\n",
    "        'F1 Score': f'{f1:.3f} [{f1_ci[0]:.3f}-{f1_ci[1]:.3f}]',\n",
    "        'MCC': f'{mcc:.3f} [{mcc_ci[0]:.3f}-{mcc_ci[1]:.3f}]'\n",
    "    })\n",
    "\n",
    "# 找到AUC最大的模型\n",
    "max_auc_model = max(roc_data, key=lambda x: roc_data[x]['auc'])\n",
    "\n",
    "# 创建新的figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 最后绘制最大模型（红色加粗）\n",
    "max_data = roc_data[max_auc_model]\n",
    "plt.plot(max_data['fpr'], max_data['tpr'], \n",
    "         color='red', \n",
    "         lw=2,\n",
    "         label=f\"AUC={max_data['auc']:.3f} [{max_data['auc_ci'][0]:.3f}-{max_data['auc_ci'][1]:.3f}]\")\n",
    "\n",
    "# 按指定顺序绘制非最大模型\n",
    "for name in models_order:\n",
    "    if name == max_auc_model or name not in roc_data:\n",
    "        continue\n",
    "        \n",
    "    data = roc_data[name]\n",
    "    plt.plot(data['fpr'], data['tpr'], \n",
    "             color=model_colors[name],\n",
    "             alpha=0.33, \n",
    "             lw=1,\n",
    "             label=f\"AUC={data['auc']:.3f} [{data['auc_ci'][0]:.3f}-{data['auc_ci'][1]:.3f}]\")\n",
    "\n",
    "\n",
    "\n",
    "# 绘制随机猜测线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "# 设置样式\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", frameon=False)\n",
    "\n",
    "# 移除右边和上边边界\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "# 保存结果\n",
    "plt.savefig('外部测试ROC.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 将结果转换为DataFrame并显示\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# 将结果数据框保存为CSV文件\n",
    "results_df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 遍历每个模型，绘制混淆矩阵\n",
    "for name, model in best_models.items():\n",
    "    # 使用最佳模型进行预测\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    # 将混淆矩阵数值转换为百分比\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # 创建一个图形\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # 使用Seaborn的heatmap绘制混淆矩阵，数值用百分数表示\n",
    "    sns.heatmap(cm_percentage, annot=False, fmt=\".2f\", cmap='Blues', cbar=True, square=True,\n",
    "                xticklabels=['Negative', 'Positive'], \n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    \n",
    "    # 添加数字到热图上，使用反色\n",
    "    for i in range(cm_percentage.shape[0]):\n",
    "        for j in range(cm_percentage.shape[1]):\n",
    "            # 根据百分比值设置文本颜色\n",
    "            color = 'black' if cm_percentage[i, j] < 50 else 'white'\n",
    "            plt.text(j + 0.5, i + 0.5, f\"{cm_percentage[i, j]:.2f}%\", \n",
    "                     ha='center', va='center', color=color, fontsize=12)\n",
    "    \n",
    "    # 添加标题和标签\n",
    "    plt.title(f'{name} Confusion Matrix (Percentage)', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    # 显示混淆矩阵\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存为文件\n",
    "    plt.savefig('{name}_confusion_matrix.svg', format='svg')\n",
    "    \n",
    "    # 显示图像\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存每个最佳模型\n",
    "for name, model in best_models.items():\n",
    "    joblib.dump(model, 'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_hmad/model/{name}_model.pkl')\n",
    "    print(f\"{name} model saved successfully.\")\n",
    "\n",
    "# 加载模型\n",
    "# loaded_model = joblib.load('D:/adult_dep/new_ML/output_new/Logistic Regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新后\n",
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化结果存储目录\n",
    "output_dir = 'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_hmad/'\n",
    "\n",
    "# 特征数量\n",
    "num_features = X_test.shape[1]\n",
    "max_evals = 2 * num_features + 1\n",
    "\n",
    "# 存储所有模型的 SHAP 值\n",
    "shap_values_dict = {}\n",
    "\n",
    "# 逐一处理每个模型并保存 SHAP 值为 CSV 文件\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Processing SHAP for {name}...\")\n",
    "    \n",
    "    # 创建 SHAP 解释器\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        explainer = shap.Explainer(model.predict_proba, mirna_feature)\n",
    "    else:\n",
    "        explainer = shap.Explainer(model.predict, mirna_feature)\n",
    "\n",
    "    # 计算 SHAP 值\n",
    "    shap_values = explainer(X_test, max_evals=max_evals)\n",
    "\n",
    "    # 如果是二分类模型，选择 SHAP 值中的正类（假设类别 1）\n",
    "    if len(shap_values.values.shape) == 3:\n",
    "        shap_values_selected = shap_values[..., 1]  # 提取正类的 SHAP 值\n",
    "    else:\n",
    "        shap_values_selected = shap_values  # 对于其他模型直接使用\n",
    "\n",
    "    # 保存 SHAP 值到字典\n",
    "    shap_values_dict[name] = shap_values_selected\n",
    "\n",
    "    # 保存 SHAP 值为 CSV 文件\n",
    "    output_path_csv = f'{output_dir}allrna_{name}_shap_values.csv'\n",
    "    pd.DataFrame(shap_values_selected.values, columns=X_test.columns).to_csv(output_path_csv, index=False)\n",
    "    print(f\"SHAP values for {name} saved to {output_path_csv}\")\n",
    "\n",
    "\n",
    "    # 绘制 SHAP 摘要图\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values_selected, X_test, max_display=20, show=False)\n",
    "\n",
    "    # 保存 SHAP 图为 SVG 格式\n",
    "    output_path_plot = f'{output_dir}allrna_{name}_shap.svg'\n",
    "    plt.savefig(output_path_plot, format='svg')\n",
    "    plt.close()\n",
    "    print(f\"SHAP plot for {name} saved to {output_path_plot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义颜色\n",
    "start_color = np.array([0, 51, 102])  # 深蓝色\n",
    "end_color = np.array([255, 140, 0])   # 橘黄色\n",
    "\n",
    "# 生成渐变\n",
    "num_colors = 10\n",
    "gradient_colors = [start_color + (end_color - start_color) * (i / (num_colors - 1)) for i in range(num_colors)]\n",
    "gradient_colors = np.array(gradient_colors) / 255  # 归一化为0到1\n",
    "\n",
    "# 初始化结果存储目录\n",
    "output_dir = 'C:/Users/74101/Desktop/成人抑郁症/result/10.22/result/all_hmad/'\n",
    "\n",
    "# cmap = plt.colors.ListedColormap(['#003366', '#FF8C00'])  # 深蓝色和橘黄色\n",
    "cmap = ListedColormap(gradient_colors)\n",
    "\n",
    "# 从 CSV 文件读取 SHAP 值并绘制 SHAP 摘要图，保存为 PDF\n",
    "for name in best_models.keys():\n",
    "    print(f\"Generating SHAP plot for {name} from CSV...\")\n",
    "\n",
    "    # 读取 CSV 文件中的 SHAP 值\n",
    "    input_path_csv = f'{output_dir}allrna_{name}_shap_values.csv'\n",
    "    shap_values_selected = pd.read_csv(input_path_csv)\n",
    "\n",
    "    # 绘制 SHAP 摘要图\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values_selected.values, X_test, max_display=5, show=False, cmap = cmap)\n",
    "\n",
    "    # 保存 SHAP 图为 PDF 格式\n",
    "    output_path_pdf = f'{output_dir}allrna_{name}_shap.pdf'\n",
    "    plt.savefig(output_path_pdf, format='pdf')\n",
    "    plt.close()\n",
    "    print(f\"SHAP plot for {name} saved to {output_path_pdf}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
